{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "virtual-culture",
   "metadata": {},
   "outputs": [],
   "source": [
    "#File: dataPreprocessing.ipynb\n",
    "#Purpose: data preprocessing for steve mapping dataset\n",
    "#Author: Quan Gan, Yuxuan Zhou\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "muslim-virus",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('steve_mapping_1000.csv', skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "welsh-turning",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = df[['collectionCode', 'habitat', 'higherGeography', 'locality','higherClassification', 'Steve label']]\n",
    "count = 0\n",
    "\n",
    "for index,row in info.iteritems():\n",
    "\n",
    "    #recrods' labels clean\n",
    "    info = info.replace(np.nan, \"\", regex=True)\n",
    "    info = info[info['Steve label'] != \"\"]\n",
    "    info = info.replace('\\n', \" \", regex=True)\n",
    "    info = info.replace('Lake,', \"Lake\", regex=True)\n",
    "      \n",
    "    #add prefix \"__label__\" to labels\n",
    "    labels = info['Steve label'].str.split(r', ', expand=True)\n",
    "    labels = labels.rename(columns= {0: \"label1\", 1: \"label2\"})\n",
    "    labels['label1'] = \"__label__\" + labels['label1']\n",
    "    labels = labels.fillna(\"\")\n",
    "    labels.loc[labels['label2'] != \"\", 'label2'] = \"__label__\"+labels.loc[labels['label2'] != \"\"]['label2'] \n",
    "    \n",
    "    if count <= 4:\n",
    "        info = info.drop(columns = [index])\n",
    "    \n",
    "    result = labels.replace(\" \", \"_\", regex=True)\n",
    "        \n",
    "    #records' text clean\n",
    "    info['text'] = np.array([ '' for i in range(995)])\n",
    "    \n",
    "    for new_index, new_row in info.iteritems():\n",
    "        if new_index != str('text') and new_index != str('Steve label'):\n",
    "            info['text'] += info[new_index] + \" \" \n",
    "    \n",
    "    info['text'] = info['text'].str.strip()\n",
    "    info['text'] = info['text'].str.replace('[^\\w\\s]','',regex = True)\n",
    "    info['text'] = info['text'].str.lower()\n",
    "     \n",
    "    #sample records to trainset and testset\n",
    "    result['label'] = result['label1'] + \" \" + result['label2']\n",
    "    result['text'] = info['text']\n",
    "    ds = result['label'] + \" \" + result['text']\n",
    "    \n",
    "    name = ['collectionCode', 'habitat', 'higherGeography', 'locality','higherClassification', 'full']\n",
    "    ds.to_csv(r'cleanedData' + \"_\" + name[count] + \"_remove\" + '.txt', header=False, index=False)\n",
    "\n",
    "    f = open('title.txt', 'a')  \n",
    "    f.write('cleanedData' + \"_\" + name[count] + \"_remove\" + '.txt\\n')\n",
    "    info = df[['collectionCode', 'habitat', 'higherGeography', 'locality','higherClassification', 'Steve label']]\n",
    "    count += 1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "frozen-benjamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid the same file name appearing multiple times\n",
    "p = open(\"title.txt\", \"r\")\n",
    "line = list(set(p.readlines()))\n",
    "\n",
    "r = open('new_title.txt', 'w')\n",
    "for i in line:\n",
    "    r.write(i)\n",
    "\n",
    "r.close()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-penny",
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
