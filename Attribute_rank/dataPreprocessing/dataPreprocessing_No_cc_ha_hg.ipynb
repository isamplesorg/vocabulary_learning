{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "virtual-culture",
   "metadata": {},
   "outputs": [],
   "source": [
    "#File: dataPreprocessing.ipynb\n",
    "#Purpose: data preprocessing for steve mapping dataset\n",
    "#Author: Quan Gan\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "muslim-virus",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('steve_mapping_1000.csv', skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "welsh-turning",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = df[['locality','higherClassification', 'Steve label']]\n",
    "count = 0\n",
    "for index,row in info.iteritems():\n",
    "    #recrods' labels clean\n",
    "    info = info.replace(np.nan, \"\", regex=True)\n",
    "    info = info[info['Steve label'] != \"\"]\n",
    "    info = info.replace('\\n', \" \", regex=True)\n",
    "    info = info.replace('Lake,', \"Lake\", regex=True)\n",
    "    \n",
    "    #add prefix \"__label__\" to labels\n",
    "    labels = info['Steve label'].str.split(r', ', expand=True)\n",
    "    labels = labels.rename(columns= {0: \"label1\", 1: \"label2\"})\n",
    "    labels['label1'] = \"__label__\" + labels['label1']\n",
    "    labels = labels.fillna(\"\")\n",
    "    labels.loc[labels['label2'] != \"\", 'label2'] = \"__label__\"+labels.loc[labels['label2'] != \"\"]['label2'] \n",
    "    \n",
    "    result = labels.replace(\" \", \"_\", regex=True)\n",
    "    \n",
    "    info['text'] = np.array([ '' for i in range(995)])\n",
    "    #records' text clean\n",
    "    for new_index, new_row in info.iteritems():\n",
    "        info['text'] += info[new_index] + \" \"\n",
    "    \n",
    "    info['text'] = info['text'].str.replace('[^\\w\\s]','',regex = True)\n",
    "    info['text'] = info['text'].str.lower()\n",
    "    \n",
    "    info = info.drop(columns = [index])\n",
    "    \n",
    "    #sample records to trainset and testset\n",
    "    result['label'] = result['label1'] + \" \" + result['label2']\n",
    "    result['text'] = info['text']\n",
    "    ds = result['label'] + \" \" + result['text']\n",
    "    train = ds.sample(frac=0.7, random_state=99) #randomly choose 70% records as trainset\n",
    "    test = ds.loc[~ds.index.isin(train.index)] #rest 30% records as testset\n",
    "    \n",
    "    name = ['full', 'locality','higherClassification']\n",
    "    \n",
    "    ds.to_csv(r'cleanedData' + name[count] + \"_remove\" + '.txt', header=False, index=False)\n",
    "    train.to_csv(r'steve_696.train', header=False, index=False)\n",
    "    test.to_csv(r'steve_299.valid', header=False, index=False)   \n",
    "    \n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-prison",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
