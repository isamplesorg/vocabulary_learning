{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#File: dataPreprocessing.ipynb\n",
    "#Purpose: data preprocessing for steve mapping dataset\n",
    "#Author: Quan Gan\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df = pd.read_csv('../data/Raw data/steve_mapping_1000.csv', skiprows = 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "info = df[['collectionCode', 'habitat', 'higherGeography', 'locality', 'higherClassification', 'Steve label']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#recrods' labels clean\n",
    "info = info.replace(np.nan, \"\", regex=True)\n",
    "info = info[info['Steve label'] != \"\"]\n",
    "info = info.replace('\\n', \" \", regex=True)\n",
    "info = info.replace('Lake,', \"Lake\", regex=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#add prefix \"__label__\" to labels\n",
    "labels = info['Steve label'].str.split(r', ', expand=True)\n",
    "labels = labels.rename(columns= {0: \"label1\", 1: \"label2\"})\n",
    "labels['label1'] = \"__label__\" + labels['label1']\n",
    "labels = labels.fillna(\"\")\n",
    "labels.loc[labels['label2'] != \"\", 'label2'] = \"__label__\"+labels.loc[labels['label2'] != \"\"]['label2'] "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "result = labels.replace(\" \", \"_\", regex=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#records' text clean\n",
    "info['text'] = info['collectionCode'] + \" \" + info['habitat'] + \" \" + info['higherGeography'] + \" \" + info['locality'] + \" \" + info['higherClassification']\n",
    "info['text'] = info['text'].str.replace('[^\\w\\s]','')\n",
    "info['text'] = info['text'].str.lower()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/var/folders/3m/_4pt01ws7ks9h8k6fp1bp2qw0000gn/T/ipykernel_42087/4128483157.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  info['text'] = info['text'].str.replace('[^\\w\\s]','')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "#sample records to trainset and testset\n",
    "result['label'] = result['label1'] + \" \" + result['label2']\n",
    "result['text'] = info['text']\n",
    "ds = result['label'] + \" \" + result['text']\n",
    "train = ds.sample(frac=0.7, random_state=99) #randomly choose 70% records as trainset\n",
    "test = ds.loc[~ds.index.isin(train.index)] #rest 30% records as testset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "train.to_csv(r'../data/steve_696.train', header=False, index=False)\n",
    "test.to_csv(r'../data/steve_299.valid', header=False, index=False)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}