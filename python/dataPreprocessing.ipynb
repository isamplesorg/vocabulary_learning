{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#File: dataPreprocessing.ipynb\r\n",
    "#Purpose: data preprocessing for steve mapping dataset\r\n",
    "#Author: Quan Gan\r\n",
    "import pandas as pd\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df = pd.read_csv('../data/Raw_data/steve_mapping_1000.csv', skiprows = 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "info = df[['collectionCode', 'habitat', 'higherGeography', 'locality', 'higherClassification', 'Steve label']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#recrods' labels clean\r\n",
    "info = info.replace(np.nan, \"\", regex=True)\r\n",
    "info = info[info['Steve label'] != \"\"]\r\n",
    "info = info.replace('\\n', \" \", regex=True)\r\n",
    "info = info.replace('Lake,', \"Lake\", regex=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#add prefix \"__label__\" to labels\r\n",
    "labels = info['Steve label'].str.split(r', ', expand=True)\r\n",
    "labels = labels.rename(columns= {0: \"label1\", 1: \"label2\"})\r\n",
    "labels['label1'] = \"__label__\" + labels['label1']\r\n",
    "labels = labels.fillna(\"\")\r\n",
    "labels.loc[labels['label2'] != \"\", 'label2'] = \"__label__\"+labels.loc[labels['label2'] != \"\"]['label2'] "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "result = labels.replace(\" \", \"_\", regex=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#records' text clean\r\n",
    "info['text'] = info['collectionCode'] + \" \" + info['habitat'] + \" \" + info['higherGeography'] + \" \" + info['locality'] + \" \" + info['higherClassification']\r\n",
    "info['text'] = info['text'].str.replace('[^\\w\\s]','')\r\n",
    "info['text'] = info['text'].str.lower()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\gq121\\AppData\\Local\\Temp/ipykernel_12300/4128483157.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  info['text'] = info['text'].str.replace('[^\\w\\s]','')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "#sample records to trainset and testset\r\n",
    "result['label'] = result['label1'] + \" \" + result['label2']\r\n",
    "result['text'] = info['text']\r\n",
    "ds = result['label'] + \" \" + result['text']\r\n",
    "train = ds.sample(frac=0.7, random_state=99) #randomly choose 70% records as trainset\r\n",
    "test = ds.loc[~ds.index.isin(train.index)] #rest 30% records as testset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "ds.to_csv(r'../data/cleanedData.txt', header=False, index=False)\r\n",
    "train.to_csv(r'../data/steve_696.train', header=False, index=False)\r\n",
    "test.to_csv(r'../data/steve_299.valid', header=False, index=False)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit"
  },
  "interpreter": {
   "hash": "c5562ae4cb73c005d4d512b63371f9759c2bba9f1255843d95070cdaa5df3d5e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}