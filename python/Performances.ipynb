{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit"
  },
  "interpreter": {
   "hash": "c5562ae4cb73c005d4d512b63371f9759c2bba9f1255843d95070cdaa5df3d5e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#File: Performances.ipynb\r\n",
    "#Purpose: find best parameters to train fastText model\r\n",
    "#Author: Quan Gan\r\n",
    "import fasttext\r\n",
    "import csv "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#Method: sortHelper\r\n",
    "#Purpose: result list sorting helper\r\n",
    "def sortHelper(e):\r\n",
    "    return e['precision']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#Method: getPerformance\r\n",
    "#Purpose: train different fasttext models with different parameters and return performances\r\n",
    "#Parameters: input_train -> the trainset file path\r\n",
    "#            input_word_vector -> pretained word vector file path\r\n",
    "#            input_test -> the testset file path\r\n",
    "def getPerformance(input_train, input_word_vector, input_test):\r\n",
    "    result = []\r\n",
    "    for lr in [0.1, 0.5, 1]:\r\n",
    "        for epoch in [5, 10, 15, 20, 25]:\r\n",
    "            model = fasttext.train_supervised(input = input_train,\r\n",
    "                                              dim = 300,\r\n",
    "                                              lr = lr,\r\n",
    "                                              epoch = epoch,\r\n",
    "                                              loss ='ova',\r\n",
    "                                              pretrainedVectors = input_word_vector)\r\n",
    "            for k in range(1, 6):\r\n",
    "                Performance = model.test(input_test, k=k)\r\n",
    "                result.append({'precision' : Performance[1], 'recall' : Performance[2], 'k':k, 'learning rate' : lr, 'epoch': epoch})\r\n",
    "    result.sort(key=sortHelper, reverse=True)\r\n",
    "    return result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#Method: output_to_csv\r\n",
    "#Purpose: convert result performances into csv file\r\n",
    "#Parameters: fileName -> the filename without file extension (the file will be stored in current file location)\r\n",
    "#            result -> the performances result\r\n",
    "def output_to_csv(fileName, result):\r\n",
    "    keys = ['precision', 'recall', 'k', 'learning rate','epoch']\r\n",
    "    with open(fileName + '.csv', 'w', newline='') as output_file:\r\n",
    "        writer = csv.DictWriter(output_file, keys)\r\n",
    "        writer.writeheader()\r\n",
    "        writer.writerows(result)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#model trained by steve mapping\r\n",
    "steve_result = getPerformance(\"../data/steve_696.train\", \"../data/crawl-300d-2M-subword.vec\", \"../data/steve_299.valid\")\r\n",
    "output_to_csv(\"../data/Performance_result/steve_performance\", steve_result)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Read 0M words\n",
      "Number of words:  2717\n",
      "Number of labels: 6\n",
      "Progress: 100.0% words/sec/thread: 1540619 lr:  0.000000 avg.loss:  0.026534 ETA:   0h 0m 0s\n",
      "Read 0M words\n",
      "Number of words:  2717\n",
      "Number of labels: 6\n",
      "Progress: 100.0% words/sec/thread: 1631473 lr:  0.000000 avg.loss:  0.018439 ETA:   0h 0m 0s\n",
      "Read 0M words\n",
      "Number of words:  2717\n",
      "Number of labels: 6\n",
      "Progress: 100.0% words/sec/thread: 1657169 lr:  0.000000 avg.loss:  0.009325 ETA:   0h 0m 0s\n",
      "Read 0M words\n",
      "Number of words:  2717\n",
      "Number of labels: 6\n",
      "Progress: 100.0% words/sec/thread: 1738231 lr:  0.000000 avg.loss:  0.010632 ETA:   0h 0m 0s\n",
      "Read 0M words\n",
      "Number of words:  2717\n",
      "Number of labels: 6\n",
      "Progress: 100.0% words/sec/thread: 1701359 lr:  0.000000 avg.loss:  0.006012 ETA:   0h 0m 0s\n",
      "Read 0M words\n",
      "Number of words:  2717\n",
      "Number of labels: 6\n",
      "Progress: 100.0% words/sec/thread: 1544349 lr:  0.000000 avg.loss:  0.008524 ETA:   0h 0m 0s\n",
      "Read 0M words\n",
      "Number of words:  2717\n",
      "Number of labels: 6\n",
      "Progress: 100.0% words/sec/thread: 1633818 lr:  0.000000 avg.loss:  0.005329 ETA:   0h 0m 0s\n",
      "Read 0M words\n",
      "Number of words:  2717\n",
      "Number of labels: 6\n",
      "Progress: 100.0% words/sec/thread: 1666123 lr:  0.000000 avg.loss:  0.003646 ETA:   0h 0m 0s\n",
      "Read 0M words\n",
      "Number of words:  2717\n",
      "Number of labels: 6\n",
      "Progress: 100.0% words/sec/thread: 1690460 lr:  0.000000 avg.loss:  0.002342 ETA:   0h 0m 0s\n",
      "Read 0M words\n",
      "Number of words:  2717\n",
      "Number of labels: 6\n",
      "Progress: 100.0% words/sec/thread: 1738199 lr:  0.000000 avg.loss:  0.000992 ETA:   0h 0m 0s\n",
      "Read 0M words\n",
      "Number of words:  2717\n",
      "Number of labels: 6\n",
      "Progress: 100.0% words/sec/thread: 1541068 lr:  0.000000 avg.loss:  0.007790 ETA:   0h 0m 0s\n",
      "Read 0M words\n",
      "Number of words:  2717\n",
      "Number of labels: 6\n",
      "Progress: 100.0% words/sec/thread: 1637158 lr:  0.000000 avg.loss:  0.002079 ETA:   0h 0m 0s\n",
      "Read 0M words\n",
      "Number of words:  2717\n",
      "Number of labels: 6\n",
      "Progress: 100.0% words/sec/thread: 1678880 lr:  0.000000 avg.loss:  0.002645 ETA:   0h 0m 0s\n",
      "Read 0M words\n",
      "Number of words:  2717\n",
      "Number of labels: 6\n",
      "Progress: 100.0% words/sec/thread: 1684023 lr:  0.000000 avg.loss:  0.002007 ETA:   0h 0m 0s\n",
      "Read 0M words\n",
      "Number of words:  2717\n",
      "Number of labels: 6\n",
      "Progress: 100.0% words/sec/thread: 1729905 lr:  0.000000 avg.loss:  0.000946 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "#model trained by speciment type SESAR\r\n",
    "SESAR_result = getPerformance(\"../Collections_data/SESARtrain_specimenType.train\", \"../data/crawl-300d-2M-subword.vec\", \"../Collections_data/SESARValid_specimenType.valid\")\r\n",
    "output_to_csv(\"../data/Performance_result/SESAR_performance_specimenType\", SESAR_result)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "#model trained by material type SESAR\r\n",
    "SESAR_result = getPerformance(\"../Collections_data/SESARtrain_materialType.train\", \"../data/crawl-300d-2M-subword.vec\", \"../Collections_data/SESARValid_materialType.valid\")\r\n",
    "output_to_csv(\"../data/Performance_result/SESAR_performance_materialType\", SESAR_result)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "#model trained by sampled Feature SESAR\r\n",
    "SESAR_result = getPerformance(\"../Collections_data/SESARtrain_sampeldFeature.train\", \"../data/crawl-300d-2M-subword.vec\", \"../Collections_data/SESARValid_sampeldFeature.valid\")\r\n",
    "output_to_csv(\"../data/Performance_result/SESAR_performance_sampledFeature\", SESAR_result)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "#model trained by specimen type openContext\r\n",
    "openContext_result = getPerformance(\"../Collections_data/openContexttrain_specimenType.train\", \"../data/crawl-300d-2M-subword.vec\", \"../Collections_data/openContextValid_specimenType.valid\")\r\n",
    "output_to_csv(\"../data/Performance_result/openContext_performance_specimenType\", openContext_result)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#model trained by specimen type openContext only item category\r\n",
    "openContext_result = getPerformance(\"../Collections_data/openContexttrain_specimenType_onlyOne.train\", \"../data/crawl-300d-2M-subword.vec\", \"../Collections_data/openContextValid_specimenType_onlyOne.valid\")\r\n",
    "output_to_csv(\"../data/Performance_result/openContext_performance_specimenType_onlyOne\", openContext_result)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "#model trained by matrial type openContext only item category\r\n",
    "openContext_result = getPerformance(\"../Collections_data/openContexttrain_materialType_onlyOne.train\", \"../data/crawl-300d-2M-subword.vec\", \"../Collections_data/openContextValid_materialType_onlyOne.valid\")\r\n",
    "output_to_csv(\"../data/Performance_result/openContext_performance_materialType_onlyOne\", openContext_result )"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}