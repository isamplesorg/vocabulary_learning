{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit"
  },
  "interpreter": {
   "hash": "c5562ae4cb73c005d4d512b63371f9759c2bba9f1255843d95070cdaa5df3d5e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "#File: CollectionPredict.ipynb\r\n",
    "#Purpose: use fastText model to predict DwC different collections\r\n",
    "#Author: Quan Gan\r\n",
    "import fasttext\r\n",
    "import csv"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# 'Amphibians' refers to 'Amphibians %26 Reptiles'\r\n",
    "# 'zoology' refers to 'Invertebrate Zoology'\r\n",
    "collections = [\"Amphibians\", \"Birds\", \"Botany\", \"Entomology\", \"Fishes\", \"Mammals\", \"zoology\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "#Method: trainModel\r\n",
    "#Purpose: train fastText model\r\n",
    "#Paremater: trainSet -> the trainSet file path\r\n",
    "#           input_word_vector -> the pretrained word vector file path\r\n",
    "def trainModel(trainSet, input_word_vector):\r\n",
    "    model = fasttext.train_supervised(input = trainSet,\r\n",
    "                                      dim = 300,\r\n",
    "                                      lr = 0.5,\r\n",
    "                                      epoch = 20,\r\n",
    "                                      loss ='ova',\r\n",
    "                                      pretrainedVectors = input_word_vector)\r\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "#Method: getPredictList\r\n",
    "#Purpose: read predict file and store data into list\r\n",
    "#Parameter: filePath -> the predict file path\r\n",
    "def getPredictList(filePath):\r\n",
    "    predict_file = open(filePath, 'r')\r\n",
    "    predict_sentences = []\r\n",
    "    for line in predict_file:\r\n",
    "        predict_sentences.append(line.strip())\r\n",
    "    return predict_sentences"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "#Method: calulateProb\r\n",
    "#Purpose: calulate the average, minimum and maximum probility.\r\n",
    "#Parameter: prob -> the probility list\r\n",
    "def calulateProb(prob):\r\n",
    "    avg_prob = 0\r\n",
    "    max = -float(\"inf\")\r\n",
    "    min = float(\"inf\")\r\n",
    "    for i in prob:\r\n",
    "        avg_prob += i[0]\r\n",
    "        if max < i[0]:\r\n",
    "            max = i[0]\r\n",
    "        if min > i[0]:\r\n",
    "            min = i[0]\r\n",
    "    avg_prob = avg_prob/len(prob)\r\n",
    "    return avg_prob, max, min"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "#Method: csvResult\r\n",
    "#Purpose: store result into csv file\r\n",
    "#Parameter: prob -> the probility list\r\n",
    "def csvResult(fileName, result):\r\n",
    "    with open(\"../data/Collection_result/{}_result.txt\".format(fileName), 'w', newline='') as output_file:\r\n",
    "        for i in range(0, len(result[0])):\r\n",
    "            output_file.write(\"Label: {} - Probility: {}\\n\".format(result[0][i], result[1][i][0]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "#trian the model with simple trainset\r\n",
    "model = trainModel(\"../data/steve_696.train\", \"../data/crawl-300d-2M-subword.vec\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Read 0M words\n",
      "Number of words:  2883\n",
      "Number of labels: 6\n",
      "Progress: 100.0% words/sec/thread: 1497396 lr:  0.000000 avg.loss:  0.002422 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "probPredict = []\r\n",
    "for i in collections:\r\n",
    "    predictList = getPredictList(\"../data/Collection_predict/{}_predict.txt\".format(i))\r\n",
    "    result = model.predict(predictList, k=1)\r\n",
    "    csvResult(i, result)\r\n",
    "    avg, max, min = calulateProb(result[1])\r\n",
    "    probPredict.append({\"Collcetion\": i, \"Average_prob\": avg, \"Max_prob\": max, \"Min_prob\": min})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "#Method: output_to_csv\r\n",
    "#Purpose: convert result performances into csv file\r\n",
    "#Parameters: fileName -> the filename without file extension (the file will be stored in current file location)\r\n",
    "#            result -> the performances result\r\n",
    "def output_to_csv(fileName, result):\r\n",
    "    keys = ['Collcetion', 'Average_prob', 'Max_prob', 'Min_prob']\r\n",
    "    with open(fileName + '.csv', 'w', newline='') as output_file:\r\n",
    "        writer = csv.DictWriter(output_file, keys)\r\n",
    "        writer.writeheader()\r\n",
    "        writer.writerows(result)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "output_to_csv(\"../data/Collection_result/Sum_Result\", probPredict)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}